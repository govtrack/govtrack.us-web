{% extends "master.html" %}
{% load cache humanize %}
{% load govtrack_utils %}

{% block title %}GovTrack.us Analysis Methodology{% endblock %}

{% block crumbs %}
<nav aria-label="breadcrumb">
  <ol class="breadcrumb">
    <li class="breadcrumb-item"><a href="/about">About GovTrack</a></li>
  </ol>
</nav>

{% endblock %}

{% block body_scripts %}
<script src="{{ STATIC_URL }}vendor/highcharts.js"></script>
<script type="text/javascript" src="{{ STATIC_URL }}js/charts.js"></script>

<script>
	{% cache 12000 analysis_methods_ideology %}
	for (var i = 1; i <= 2; i++) {
		make_sponsorship_chart("sponsorship_analysis_chart_senate"+i, 'Senate ({{ideology.senate.start_date|date}} to {{ideology.senate.end_date|date}})', {{ideology.senate.series|safe}}, false);
		make_sponsorship_chart("sponsorship_analysis_chart_house"+i, 'House ({{ideology.house.start_date|date}} to {{ideology.house.end_date|date}})', {{ideology.house.series|safe}}, false);
	}
	{% endcache %}

	{% for m in prognosis_test %}
		make_line_chart("prognosis_accuracy_{{m.bill_type}}_{{m.is_introduced_model}}",
			null,
			"Prognosis",
			"% {% if m.is_introduced_model %}out of committee{% else %}{{m.success_name}}{% endif %}",
			[{ data: [{% for bin, n, success in m.bins %}{ x: Math.round({{bin|floatformat:2}}*10)/10, y: Math.round({{success|floatformat:3}}*1000)/10 }{% if not forloop.last %}, {% endif %}{% endfor %} ]}],
			{
				width: 400,
				height: 250,
				ymin: 0,
				xmin: 0,
				xunit: "% Prognosis",
				yunit: "% Successful",
			});
		
			make_line_chart("prognosis_precisionrecall_{{m.bill_type}}_{{m.is_introduced_model}}",
				null,
				"Precision (%)",
				"Recall (%)",
				[{ data: [{% for pt in m.precision_recall %}{ t: Math.round({{pt.threshold|floatformat:1}}*10)/10, x: Math.round({{pt.precision|floatformat:3}}*1000)/10, y: Math.round({{pt.recall|floatformat:3}}*1000)/10 }{% if not forloop.last %}, {% endif %}{% endfor %} ]}],
				{
					width: 400,
					height: 250,
					ymin: 0,
					ymax: 100,
					xmin: 0,
					xmax: 100,
					xunit: "% Precision",
					yunit: "% Recall",
					tooltip: function() { return "t=" + this.point.t + "%: " + this.point.x + "% Precision, " + this.point.y + "% Recall"; }
				});
	{% endfor %}	
</script>
{% endblock %}

{% block extra_css %}
<style>
#content h2 { margin: 1em 0; }
h3 { margin: 1em 0; }
</style>
{% endblock %}

{% block body %}
	<h1>Analysis Methodology</h1>
	<p>Statistical analyses of legislation and legislators provide context for the legislative process.
	Of all of the 10,000+ bills pending at any given time, our unique analyses help GovTrack visitors know
	what is relevant and what to pay attention to.</p>

<ul class="nav nav-tabs" role="tablist">
	<li class="nav-item" role="presentation"><a href="#overview" aria-controls="overview" class="nav-link active" data-bs-toggle="tab" aria-selected="true" role="tab">Overview</a></li>
	<li class="nav-item" role="presentation"><a href="#ideology" aria-controls="ideology" class="nav-link" data-bs-toggle="tab" aria-selected="true" role="tab">Ideology</a></li>
	<li class="nav-item" role="presentation"><a href="#leadership" aria-controls="leadership" class="nav-link" data-bs-toggle="tab" aria-selected="true" role="tab">Leadership</a></li>
	<li class="nav-item" role="presentation"><a href="#textincorporation" aria-controls="textincorporation" class="nav-link" data-bs-toggle="tab" aria-selected="true" role="tab">Text Incorporation</a></li>
	<li class="nav-item" role="presentation"><a href="#prognosis" aria-controls="prognosis" class="nav-link" data-bs-toggle="tab" aria-selected="true" role="tab">Prognosis</a></li>
</ul>

<div class="tab-content">
	<div id="overview" class="tab-pane active">
		<div class="row">
		<div class="col-md-6">
			<h3>Ideology</h3>
			<p>The <a href="#ideology">Ideology Analysis</a> compares the sponsorship and cosponsorship patterns of Members of Congress. <a href="#ideology">Read More &raquo;</a></p>
		</div>
	
		<div class="col-md-6">
			<h3>Prognosis</h3>
			<p>The <a href="#prognosis">Prognosis Analysis</a> looks at the factors that help or hurt a bill&rsquo;s chance of getting out of committee and being enacted. It is based on a regression model. <a href="#prognosis">Read More &raquo;</a></p>
		</div>
		</div>
		<div class="row">
		<div class="col-md-6">
			<h3>Leadership</h3>
			<p>The <a href="#leadership">Leadership Analysis</a> looks at who is cosponsoring whose bills to see who the legislative leaders are. It&rsquo;s a little like if you scratch my back will I scratch yours? The analysis is based on Google PageRank, the algorithm Google uses to order search results. <a href="#leadership">Read More &raquo;</a></p>
		</div>
		</div>
	</div> <!-- /overview pane -->
	
	<div id="ideology" class="tab-pane">
		<h2>Ideology Analysis of Members of Congress</h2>
		
		<div class="row">
		<div class="col-md-6">
			<p>The ideology analysis assigns a left&ndash;right score to each Member of Congress based on their pattern of cosponsorship.
			The left&ndash;right score reflects the dominant ideological difference or differences among Members of Congress, which changes over time.</p>
			
			<p>In a nutshell, Members of Congress who cosponsor similar sets of bills will get scores close together, while Members of Congress who sponsor different sets of bills will have scores far apart. Members of Congress with similar political views will tend to cosponsor the same set of bills, or bills by the same set of authors, and inversely Members of Congress with different political views will tend to cosponsor different bills.</p>
			
			<p>You can find this analysis on the pages for current Members of Congress
			and in the charts to the right which plot the ideology score on the horizontal axis and the <a href="#leadership">leadership</a> score on the vertical axis.</p>
			
			<h3>Overview</h3>
			
			<p>The data that goes into this analysis is a list of who sponsored or cosponsored which bills. The process doesn’t look at the content of the bills or the party affiliation or anything else about the Members of Congress, but it is able to infer underlying behavioral patterns, some of which correspond to real-world concepts like left-right ideology.</p>
			
			<p>You’ll see in the charts on the right that the ideology analysis does a good job at separating the Democrats from the Republicans, and within each party the moderates from the extremes. If you wanted to know how your representatives stood in relation to their peers ideologically, this chart is a good place to start.</p>
			
			<p>But keep in mind its limitations: Although we don&rsquo;t report a margin of error, the scores fluctuate significantly over time because of the limited data used in the analysis and that legislating is a process involving chance. In addition, while we sometimes refer to this as a left-right score, that&rsquo;s something we attribute to the analysis after we see the results &mdash; it may be measuring something else, perhaps something more closely related to partisan-ness, and it may be affected by the popularity of a legislator since the analysis looks at when legislators work together. Additionally, cosponsorship is a low-risk legislative action that might not reflect how a legislator might vote when forced to make yes-or-no decisions. And our scores may be gamed by legislators who cosponsor bills with the intent to move their score to the left or right.</p>
			
			<p>We first began publishing this analysis in 2004, then calling it a political spectrum. A similar analysis by <a href="http://pooleandrosenthal.com/recentpolitics.htm">Professor Keith Poole</a> using voting records rather than cosponsorship produces similar results: see <a href="http://www.voteview.com">voteview.com</a>. (As far as we know, we were the first to apply this sort of analysis to cosponsorship behavior.)</p>
			
			<h3>Methodology</h3>
			
			<p>The statistical method behind this analysis is Principal Components Analysis, also known as dimensionality reduction. Principal Components Analysis is a statistical technique that reveals underlying patterns in data.</p>
			
			<p>Here&rsquo;s how it works: Form a matrix (a grid of numbers) with columns representing Members of Congress and rows also representing Members of Congress. Do this for the House and Senate separately. We include (co)sponsorship from the current and previous two Congresses, so between four and six years of data. For the Senate, you have a 100x100 table. In each cell of the table, put the number of times the senator for the row cosponsored a bill introduced by the senator for the column. Or if it's the same senator in the row and column, put in the number of bills he or she introduced. Then compute the singular value decomposition of the matrix (which is how Principal Components Analysis is often done).</p>
			
			<p>Every square matrix has a singular value decomposition which can be interpreted as a set of sets of scores for each Member of Congress, each set a ranking on different dimension. The dimensions are themselves ranked in order by how much of the original data they explain. We have found that the <i>second</i> dimension best corresponds with what people generally consider political ideology. We use the scores from that dimension in our charts.</p>
			
			<p>The analysis is blind to actual information like what the legislation is about or what party each Member of Congress is affiliated with. In fact, there’s no guarantee that the scores have anything to do with liberal- or conversative-ness or any other standard frame for political ideology. All it tells us is how to spread Members of Congress out along a spectrum in a way that explains their record of cosponsorship. But in practice it captures left-right ideology very well.</p>

			<h3>Data</h3>
			
			<p>The ideology scores can be found in two CSV files sponsorshipanalysis_h.txt and sponsorshipanalysis_s.txt (House and Senate) over <a href="/data/analysis/by-congress/{{current_congress}}/">here</a>.</p>

			
			<h3>Source Code</h3>
			
			<p>Running this analysis is pretty simple in Python. It is literally two lines. Assuming you have the cosponsorship matrix in <tt>P</tt>:</p>
			
			<pre class="code">u, s, vT = numpy.linalg.svd(P)
ideology = vT[1,:]</pre>
	
			<p>The full source code for this analysis can be found <a href="https://github.com/govtrack/govtrack.us-web/blob/master/analysis/sponsorship_analysis.py">on github</a>.</p>
			
			<h3>Citation</h3>
			
			<p>To cite our methodology and results, we recommend either of these:</p>
			
			<p>GovTrack.us. 2013. Ideology Analysis of Members of Congress. Accessed at {{request.build_absolute_uri}}.</p>
			
			<p><a href="http://razor.occams.info">Tauberer, Joshua</a>. 2012. Observing the Unobservables in the U.S. Congress, presented at Law Via the Internet 2012, Cornell Law School, October 2012. [<a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_text.pdf">text</a> | <a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_slides.pdf">slides</a> | <a href="http://law.webcast.video.cornell.edu/Mediasite/Play/8492deddd433468bbe38942e758d060d1d?catalog=4988c354-fab3-43d0-8a09-8ec79c2ecf20">video</a>]</p>
	
			<h3>References</h3>
			
			<p>For more on how to use singular value decomposition, check out:</p>
			
			<p>Wall, Rechtsteiner, and Rocha. &ldquo;<a href="http://public.lanl.gov/mewall/kluwer2002.html">Singular value decomposition and principal component analysis</a>.&rdquo; in A Practical Approach to Microarray Data Analysis. D.P. Berrar, W. Dubitzky, M. Granzow, eds. pp. 91-109, Kluwer: Norwell, MA (2003). LANL LA-UR-02-4001.</p>
		</div>
		
		{% if ideology.senate or ideology.house %}
		<div class="col-md-6">
		<div id="sponsorship_analysis_chart_senate1"> </div>
		<div id="sponsorship_analysis_chart_house1"> </div>
		</div>
		{% endif %}
		</div>
	</div> <!-- /ideology pane -->
	
	<div id="leadership" class="tab-pane">
		<h2>Leadership Analysis of Members of Congress</h2>
		
		<div class="row">
		<div class="col-md-6">
			<p>A leadership score is computed for each Member of Congress by looking at how often other Members of Congress cosponsor their bills &mdash; more or less. The analysis is based on PageRank, Google&rsquo;s algorithm for ranking pages on the web.</p>
			
			<p>The idea behind a leadership score is that if X cosponsors Y&rsquo;s bills but Y does not cosponsor X&rsquo;s bills, then X is a follower relative to Y being a leader. </p>
			
			<p>You can find this analysis on the pages for current Members of Congress.</p>
			
			<p>The charts to the right plot the leadership score on the vertical axis and the <a href="#ideology">ideology</a> score on the horizontal axis.</p>
			
			<p>There are some interesting things in this chart. There’s a distinct V-shape. Congressional leaders appear to be more extreme. There are some confounding effects to consider here. Leaders tend to be more senior members of Congress, they tend to be older, and they have had more time to participate in legislating. But somewhere among those factors there’s an interesting correlation to having an extreme political ideology.</p>
			
			<p>These leadership and ideology scores give us a view into Congress that is normally hidden to us. We can’t observe leadership. We’re not there, in Congress, to see it. We’re not in the meetings where you can see relationships form. But those relationships are known to the representatives and senators. It’s obvious to them. They know whether they lead or follow. Their staff know. This is a sort of social knowledge that is locked within the institution of Congress, unless we get a little creative with how we try to observe it.</p>
			
		
			<h3>Overview</h3>
			
			<p>The data that goes into this analysis is a list of who sponsored or cosponsored which bills. The process doesn’t look at the content of the bills or anything else about the Members of Congress, but it is able to infer underlying behavioral patterns, some of which correspond to real-world concepts like leadership.</p>
			
			<p>We first began publishing leadership scores in 2010. As far as we know, this analysis is unique to GovTrack.</p>
			

			<h3>Methodology</h3>
			
			<p>The inspiration for this analysis comes from Google’s PageRank algorithm, which governs how Google ranks the order of pages in its search results. Google’s method is widely known: the more links you get to your website from other websites, and the more links those other websites have, the higher your PageRank and the higher up in search results you appear.</p>
			
			<p>Here&rsquo;s how we apply it to Congress: the more Members of Congress that cosponsor Member X&rsquo;s bills, and the more cosponsors those other Members of Congress have, the higher X&rsquo;s leadership score.</p>
			
			<p>We start by forming a matrix (a grid of numbers) with cosponsorship data. It is the same matrix as in the <a href="#ideology">ideology analysis</a>, so see the methodology section there for details. Then we run the PageRank algorithm on the matrix, which yields a new number for each Member of Congress. That is the leadership score.</p>
			
			<p>This analysis came from a suggestion from <a href="http://www.linkedin.com/in/barillari">Joseph Barillari</a> (who GovTrack&rsquo;s creator knew in college). (The original formulation of the score for Member of Congress X was the mean across all other Members of Congress Y of the log of the number of bills sponsored by X and cosponsored by Y divided by the number of bills sponsored by Y and cosponsored by X.)</p>
			
			<h3>Data</h3>
			
			<p>The leadership scores can be found in two CSV files sponsorshipanalysis_h.txt and sponsorshipanalysis_s.txt (House and Senate) over <a href="/data/analysis/by-congress/{{current_congress}}">here</a>.</p>
	
			<h3>Source Code</h3>
			
			<p>Here is pseudo-code in Python. Assuming you have the cosponsorship matrix in <tt>P</tt>:</p>
			
			<pre class="code">x = numpy.ones( (N, 1) ) / float(N)
while True:
    y = numpy.dot(P, x)
    if onenorm(y-x) &lt; .00000000001: break
    x = y
def onenorm(u): return sum(abs(u))</pre>
	
			<p>The full source code for this analysis can be found <a href="https://github.com/govtrack/govtrack.us-web/blob/master/analysis/sponsorship_analysis.py">on github</a>.</p>
	
			<h3>Citation</h3>
			
			<p>To cite our methodology and results, we recommend either of these:</p>
			
			<p>GovTrack.us. 2013. Leadership Analysis of Members of Congress. Accessed at {{request.build_absolute_uri}}.</p>
			
			<p><a href="http://razor.occams.info">Tauberer, Joshua</a>. 2012. Observing the Unobservables in the U.S. Congress, presented at Law Via the Internet 2012, Cornell Law School, October 2012. [<a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_text.pdf">text</a> | <a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_slides.pdf">slides</a> | <a href="http://law.webcast.video.cornell.edu/Mediasite/Play/8492deddd433468bbe38942e758d060d1d?catalog=4988c354-fab3-43d0-8a09-8ec79c2ecf20">video</a>]</p>
	
			<h3>References</h3>
			
			<p>Kamvar, Sep. 2010. Numerical algorithms for personalized search in self-organizing information networks. Princeton University Press.</p>
		</div>
		
		{% if ideology.senate or ideology.house %}
		<div class="col-md-6">
		<div id="sponsorship_analysis_chart_senate2"> </div>
		<div id="sponsorship_analysis_chart_house2"> </div>
		</div>
		{% endif %}
		</div>
	</div> <!-- /leadership pane -->
	
	<div id="textincorporation" class="tab-pane">
		<h2>Text Incorporation</h2>
		
		<div class="row">
		<div class="col-md-6">
			<p>An analysis we incorporated into GovTrack in 2016 reveals when provisions of bills are incorporated into other bills. Our new tool will reveal much more about what Congress is doing, and what laws are being made, than has ever been known to the general public.</p>
			<p>All too often Congress cuts bills apart and pastes them back together — sometimes into an “omnibus.” The bills that finally get a vote are an amalgam of provisions from other bills that either can’t or won’t get a standalone vote themselves. The most important legislation is crafted this way.</p>
			<p>Congress and the President may not be enacting many new laws by the numbers, but those new laws come from an intricate web of connections that the general public has not been able to see until now. This isn’t just a matter of discovery. It is a window into how Congress really works, the processes that only insiders are normally able to see.</p>
			<p>Our text incorporation analysis finds provisions of bills that are incorporated into enacted legislation. You can trace enacted bills back to the original legislation where provisions were introduced and you can now see when bills that <i>appear</i> to have died have instead been incorported into other legislative vehicles.</p>
			<p>Only about 3% of bills will be enacted through the signature of the President or a veto override. Another 1% are identical to those bills, so-called “companion bills,” which are identified by the Congressional Research Service. Our new analysis reveals almost another 3% of bills which had substantial parts incorporated into an enacted bill in 2015–2016. To miss that last 3% is to be practically 100% wrong about how many bills are being enacted by Congress.</p>
			<p>For further details, see <a href="https://medium.com/@govtrack/how-a-complex-network-of-bills-becomes-a-law-9972b9624d36#.78yzhuz8j">How a complex network of bills becomes a law: Introducing a new data analysis of text incorporation!</a></p>
		</div>
		
		<div class="col-md-6">
			<img src="https://cdn-images-1.medium.com/max/2000/1*NvZWinghL2uzNvQlDtUfJA.png" class="img-fluid"/>
			<img src="https://cdn-images-1.medium.com/max/2000/1*BG6UV7UmjQcYalU6Fgk4Kg.png" class="img-fluid"/>
		</div>
		</div>
	</div> <!-- /leadership pane -->
	
	<div id="prognosis" class="tab-pane">
		<h2>Bill Prognosis Analysis</h2>
		
		<div class="row">
		<div class="col-md-6">
			<p>GovTrack computes a prognosis for each bill, which is the probability that the bill will be enacted. Our computation is based on factors that are correlated with successful or failed bills in the past, such as whether the sponsor is a committee chair.</p>

			<p>What is the point of this?</p>
			
			<ul class="bullets">
			<li>More than 10,000 bills will be considered by each Congress. About 7% will become law. <b>Which bills should we focus on?</b></li>
			<li>Representatives and senators, their staff, and lobbyists all know what bills are important because they have the institutional knowledge of what makes a bill important. The prognosis highlights the <b>factors that make a bill successful</b>.</li>
			</ul>
			
			<p>The prognosis scores can be found on the pages for bills throughout the site.</p>
			
			<h3>Overview</h3>
			
			<p>The data that goes into this analysis are factors that we compute for bills, such as whether the sponsor is a committee chair (see right for a full list), and whether the bill was successful. We &ldquo;train&rdquo; the model on bills from the {{prognosis_training_congress|ordinalhtml}} Congress ({{prognosis_training_congress_dates.0|date:"Y"}}-{{prognosis_training_congress_dates.1|date:"Y"}}) to compute probabilities for bills in the current Congress.</p>
			
			<p>We first began publishing prognosis scores in 2012. As far as we know, we were the first to apply this analysis to Congressional bills.
			<p>(From late 2016 to mid 2023 we published predictions made by PredictGov/Skopos Labs and put our own analysis on pause.)</p>
						
			<h3>Methodology</h3>
			
			<p>This analysis is based on a logistic regression. Logistic regression is similar to simple linear regression but it is more appropriate when modeling probabilities. We create eight separate models: For each of the four types of legislative measures (bills, joint resolutions, concurrent resolutions, and simple resolutions), we compute one model that predicts whether the bill/resolution will get out of committee and a separate model that computes, for bills/resolutions out of committee, whether the bill/resolution will be enacted or agreed to.</p>
			
			<p>The independent variables are the binary factors mentioned above and listed in the factors table at the right.</p>
			
			<p>The dependent variable is how successful the bill or resolution was. When predicting whether a bill or resolution will make it out of committee, it is a binary variable. When predicting whether a bill will be enacted or a resolution agreed to, this is a continuous variable computed as the percentage of paragraphs in the bill that appear in any enacted bill (and similarly for resolutions). We do this because there are often identical bills in Congress (so-called companion bills) and often bills are incorporated into other bills (such as omnibus bills), and we want to give the original bills credit for being successful even if the original bill itself is not enacted per se.</p>
			
			<p>The output of the logistic regression models are weights assigned to the factors, called &beta; in the table at the right. The prognosis score for a bill is computed by multiplying all of the factors together that apply to the bill (more or less, see <a href="http://en.wikipedia.org/wiki/Logistic_regression">logistic regression on Wikipedia</a> for details). The result is a number that can be interpreted as a probability.</p>
			
			<p>In choosing the factors for model, we select from a large set of plausible factors those which appear to be statistically significant on their own (using a binomial distribution). After the logistic regression, we remove factors that appear statistically non-significant and re-compute the model.</p>

			<h3>Citation</h3>
			
			<p>To cite our methodology and results, we recommend either of these:</p>
			
			<p>GovTrack.us. 2013. Bill Prognosis Analysis. Accessed at {{request.build_absolute_uri}}.</p>
			
			<p><a href="http://razor.occams.info">Tauberer, Joshua</a>. 2012. Observing the Unobservables in the U.S. Congress, presented at Law Via the Internet 2012, Cornell Law School, October 2012. [<a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_text.pdf">text</a> | <a href="http://razor.occams.info/pubdocs/2012-10-08_LVI_slides.pdf">slides</a> | <a href="http://law.webcast.video.cornell.edu/Mediasite/Play/8492deddd433468bbe38942e758d060d1d?catalog=4988c354-fab3-43d0-8a09-8ec79c2ecf20">video</a>]</p>
	
			<h3>References</h3>
			
			<p>Here is some academic work on the same subject:</p>
			
			<p>Tae Yano, Noah A. Smith, and John D. Wilkerson. 2012. "<a href="http://projects.iq.harvard.edu/ptr/files/yanosmithwilkersonbillsurvival.pdf">Textual Predictors of Bill Survival in Congressional Committees</a>," at New Directions in Analyzing Text as Data 2012, 5-6 October at Harvard.</p>
			
			<p>John Wilkerson, David Smith, Nick Stramp, and Jeremy Dashiell. 2013. "<a href="http://people.cs.umass.edu/~brenocon/smacss2015/papers/WilkersonSmithStramp2015ReuseForAJPS.pdf">Tracing the Flow of Policy Ideas in Legislatures: A Computational Approach</a>".</p>
			
		</div>
		
		<div class="col-md-6 last">
			<h3 style="margin-bottom: 1em">Results</h3>
			
			<ul class="nav nav-tabs" role="tablist">
				<li class="nav-item" role="presentation"><a href="#prognosis_factors" aria-controls="prognosis_factors" class="nav-link active" data-bs-toggle="tab" role="tab" aria-selected="true">Factors</a></li>
				<li class="nav-item" role="presentation"><a href="#prognosis_accuracy" aria-controls="prognosis_accuracy" class="nav-link" data-bs-toggle="tab" role="tab" aria-selected="true">Accuracy</a></li>
				<li class="nav-item" role="presentation"><a href="#prognosis_other" aria-controls="prognosis_other" class="nav-link" data-bs-toggle="tab" role="tab" aria-selected="true">Other Charts</a></li>
			</ul>
			
			<div class="tab-content">
			
			<div id="prognosis_factors" class="tab-pane active">
				<p>The following tables show how various factors help or hurt a bill or resolution&rsquo;s chance of making it out of committee and getting enacted (or agreed to). Two tables are given for each of the four bill types.</p>
				
				<p>In the tables, <b>N</b> is the number of bills/resolutions that had the indicated factor in the training corpus; <b>%S</b> is of bills with this factor, the percent that were successful (past committee or enacted); and <b>&beta;</b> is the regression coefficient (weight) from the prognosis analysis. Higher weights increase the bill or resolution&rsquo;s probability of success.</p>
				
				{% for m in prognosis_factors %}
					<h4 style="margin: 1.25em 0 .5em 0;">{{m.bill_type_descr|capfirst}} {{m.success_name}}</h4>
					
					<p>Overall, about {{m.success_rate|floatformat:0}}% of the {{m.count|intcomma}} {{m.bill_type_descr.lower}} {% if not m.is_introduced_model %}that got past committee{% endif %} in {{prognosis_training_congress_dates.0|date:"Y"}}-{{prognosis_training_congress_dates.1|date:"Y"}} were {{m.success_name}}. The following factors help or hurt that:</p>
					
					{% if m.factors %}
						<table style="margin: 1em 0 1em 1em; font-size: 85%;">
							<tr><th>N</th> <th>%S</th> <th>&beta;</th> <th>Factor</th></tr>
							{% for f in m.factors %}
								<tr>
									<td style="padding: .2em .5em; text-align: center;">{{f.count|intcomma}}</td>
									<td style="padding: .2em .5em; text-align: center;">{{f.success_rate|floatformat:0}}%</td>
									<td style="padding: .2em .5em; text-align: center;">{{f.regression_beta|floatformat:1}}</td>
									<td style="padding: .2em .5em">{{f.description}}</td>
								</tr>
							{% endfor %}
						</table>
					{% else %}
						<p>There were no statistically significant factors in the model.</p>
					{% endif %}
				{% endfor %}
			</div> <!-- /prognosis factors pane -->
			
			<div id="prognosis_accuracy" class="tab-pane active">
				<p>Did it work? The following charts compare the prognoses computed for bills to their actual
				rate of success. The prognosis model for these charts was trained on the {{prognosis_testing_traincongress|ordinalhtml}} Congress and tested on the {{prognosis_testing_testcongress|ordinalhtml}} Congress.</p>
				
				<p>For each regression model, the bills are divided into 10 bins by prognosis. The median prognosis is plotted on the horizontal axis and the percentage of successful bills in the bin is plotted on the vertical axis.</p> 
				
				<p>The prognosis closely estimates the actual chances of a bill getting out of committee. Though the accuracy is much less for other predictions, the
				rough upward slope in most of the charts shows that the prognosis was often predictive of a bill&rsquo;s future.</p>
			
				{% for m in prognosis_test %}
					<h4 style="margin: 1.25em 0 .5em 0;">{{m.bill_type_descr|capfirst}} {{m.success_name}}</h4>
					<div id="prognosis_accuracy_{{m.bill_type}}_{{m.is_introduced_model}}"> </div>
				{% endfor %}
			</div> <!-- /prognosis accuracy pane -->
					
			<div id="prognosis_other" class="tab-pane active">
				<p>Here are some additional charts for machine learning researchers.</p>
				
				<p>The charts below show precision vs. recall plotted parametrically for various values of
				a success-fail threshold <i>t</i>. Bills with prognosis above <i>t</i> are predicted
				successes for the purposes of these charts. The prognosis model for these charts was trained on the {{prognosis_testing_traincongress|ordinalhtml}} Congress and tested on the {{prognosis_testing_testcongress|ordinalhtml}} Congress.</p>	
				
				{% for m in prognosis_test %}
					<h4 style="margin: 1.25em 0 .5em 0;">{{m.bill_type_descr|capfirst}} {{m.success_name}}</h4>
					<div id="prognosis_precisionrecall_{{m.bill_type}}_{{m.is_introduced_model}}"> </div>
				{% endfor %}
			</div> <!-- /prognosis other pane -->
			</div> <!-- /prognosis results panes -->
		</div>
		</div>
	</div> <!-- /prognosis pane -->
</div>
{% endblock %}

